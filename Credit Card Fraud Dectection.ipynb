{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses data from [kaggle](https://www.kaggle.com) to test different methods on unbalanced data. The revelent dataset can be found [here](https://www.kaggle.com/dalpozz/creditcardfraud/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file = 'creditcard.csv'\n",
    "data = pd.read_csv(file,delimiter = ',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCR1MzQkSd0MDUlSN0NDktTN0JAkdft/KIvW6tKaSVwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1099b8908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def bar_graph(data):\n",
    "\tone = data.loc[data['Class'] == 1].values  #fraud transaction\n",
    "\tzero = data.loc[data['Class'] == 0].values  #normal transaction\n",
    "\tbar_data = [len(zero),len(one)]\n",
    "\tplt.bar(height = bar_data, left = [0,1])\n",
    "\tplt.show()\n",
    "bar_graph(data)\n",
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From the bar graph above, we can tell that the data is highly unbalanced. To deal with unbalance data, I trained a classifier on a smaller dataset with 1:1 ratio of positive and negative labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    494\n",
       "0    490\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def reSample(data,times):\n",
    "\t#Sample size = times*number of fraud transactions\n",
    "\tfraud_num = len(data.loc[data['Class'] == 1].values)\n",
    "\tnormal_num = len(data.loc[data['Class'] == 0].values)\n",
    "\t#sample_index = random.sample(range(0, normal_num), fraud_num)\n",
    "\tsample_index = np.random.choice(normal_num,(times*fraud_num))\n",
    "\tdata_sample = data.loc[sample_index]\n",
    "\tdata_sample = pd.concat([data_sample, data.loc[data['Class'] == 1]])\n",
    "\t#print (data_sample)\n",
    "\treturn data_sample\n",
    "data_sample = reSample(data,1)  #1:1\n",
    "data_sample['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Confusion Matrix??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size:  688\n",
      "Test set size:  296\n",
      "Total:  984\n",
      "0.915540540541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "data_sample = reSample(data,1)\n",
    "#Seperate input date to X and Y\n",
    "Y = data_sample['Class'].values\n",
    "data_sample = data_sample.drop('Class', axis = 1)\n",
    "X = data_sample.values\n",
    "\n",
    "#Train set and test set split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)  #random state??\n",
    "print(\"Train set size: \", len(X_train))\n",
    "print(\"Test set size: \", len(X_test))\n",
    "print(\"Total: \", len(X_train)+len(X_test))\n",
    "\n",
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression(C=1)  #C value ? test later\n",
    "log.fit(X_train, Y_train)\n",
    "prediction = log.predict(X_test)\n",
    "\n",
    "#accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (accuracy_score(Y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with different C values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C value: 0.01 Accuracy Score:  0.915540540541\n",
      "C value: 0.1 Accuracy Score:  0.935810810811\n",
      "C value: 1 Accuracy Score:  0.915540540541\n",
      "C value: 10 Accuracy Score:  0.915540540541\n",
      "C value: 100 Accuracy Score:  0.915540540541\n"
     ]
    }
   ],
   "source": [
    "c_set = [0.01,0.1,1,10,100]  #only did in one iteration\n",
    "for c_val in c_set:\n",
    "    log_2 = LogisticRegression(C = c_val, penalty = 'l2')\n",
    "    log_2.fit(X_train, Y_train)\n",
    "    prediction_2 = log_2.predict(X_test)\n",
    "    print (\"C value:\", c_val, \"Accuracy Score: \", accuracy_score(Y_test, prediction_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the best C value here is 0.1\n",
    "Update the LR model with new C value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935810810811\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression(C=0.1,penalty = 'l2')\n",
    "log.fit(X_train, Y_train)\n",
    "prediction = log.predict(X_test)\n",
    "print (accuracy_score(Y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
